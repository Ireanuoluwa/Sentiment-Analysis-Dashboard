{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (3.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moyin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moyin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "nltk.download(\"wordnet\")\n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self,doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        words_and_tags = nltk.pos_tag(tokens)\n",
    "        return [self.wnl.lemmatize(word,pos = get_wordnet_pos(tag)) \\\n",
    "                 for word,tag in words_and_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the csv file to a pandas dataframe\n",
    "path = \"C:/Users/moyin/OneDrive/Desktop/ASU/MFG 598/PROJECT/data/amazon_reviews.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Sorting the data based on the Positive and Negative Reviews and spliting them to words\n",
    "good_reviews = df[df['feedback'] == 1]\n",
    "bad_reviews = df[df['feedback'] == 0]\n",
    "good = good_reviews['verified_reviews'].tolist()\n",
    "bad = bad_reviews['verified_reviews'].tolist()\n",
    "good_str = ' '.join(good)\n",
    "bad_str = ' '.join(bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Word CLoud for Positive Reviews\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(good_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Word CLoud for Negative Reviews\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(bad_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the extra spaces in the variation column\n",
    "df['variation'] = df['variation'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing the number of each variation of the product\n",
    "df['variation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "type_df = df[df['variation'] == \"Oak Finish\"]\n",
    "feedback_counts = type_df.groupby('feedback').size()\n",
    "feedback_counts[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_reviews'].replace(' ', np.nan, inplace=True)\n",
    "df.dropna(subset=['verified_reviews'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the reviews (X) and the feedback as the target (Y)\n",
    "X = df['verified_reviews']\n",
    "y = df['feedback']\n",
    "\n",
    "# Displaying the target column (Y) on a histogram according to the number of positive reviews and negative reviews\n",
    "y.hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen in the histogram, the target column is imbalanced. Therefore, the column would be balanced using Oversampling. Oversampling is a technique which increases the number of samples of the smallest class up to the size of the biggest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = over_sampler.fit_resample(X.values.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cleaning of the data column as pass this function to the Vectorizer\n",
    "def preprocessing(message):\n",
    "    Test_punc_removed = [word for word in message if word not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords and word.lower().isalpha() and word is not None]\n",
    "    Test_punc_removed_join_clean = ' '.join(Test_punc_removed_join_clean)\n",
    "    return Test_punc_removed_join_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the array to a 1D.\n",
    "X_res = np.ravel(X_res)\n",
    "X_res.shape\n",
    "#Convert the array to a dataframe.\n",
    "X_res = pd.Series(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the balanced target column (Y) and  reviews column (X) to train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,\n",
    "                                                    stratify=y_res, \n",
    "                                                    test_size=0.25, random_state = 245)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the y_train to a histogram.\n",
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4339,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the shape of the X_train dataset.\n",
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would be using different models to predict the sentiment of the Reviews and test how well the model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model's performace\n",
    "def model_evaluate(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    Pr_train = model.predict_proba(X_train)[:,1]\n",
    "    Pr_test = model.predict_proba(X_test)[:,1]\n",
    "    class_report = classification_report(y_test, y_pred,output_dict=True)\n",
    "\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf Vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2),max_features=2000)\n",
    "# tokenizer=LemmaTokenizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BernoulliNB \n",
    "BNBmodel = BernoulliNB(alpha = 1)\n",
    "BNBmodel.fit(X_train, y_train)\n",
    "model_evaluate(BNBmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "model_evaluate(LRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I am not fully into the product\"]\n",
    "# pred_test = tfidf.transform(test)\n",
    "# BNBmodel.predict(pred_test)\n",
    "# type(X_test)\n",
    "test = pd.Series(test)\n",
    "pred_test = tfidf.transform(test)\n",
    "LRmodel.predict(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),lowercase=False)\n",
    "# X_train = vectorizer.fit_transform(X_train)\n",
    "# X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "# LRmodel.fit(X_train, y_train)\n",
    "# model_evaluate(LRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# BNBmodel = BernoulliNB(alpha = 2)\n",
    "# BNBmodel.fit(X_train, y_train)\n",
    "# model_evaluate(BNBmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# import seaborn as sns\n",
    "# SVCmodel = LinearSVC()\n",
    "# SVCmodel.fit(X_train, y_train)\n",
    "# model_evaluate(SVCmodel)\n",
    "# Y_pred = SVCmodel.predict(X_test)\n",
    "# cm = confusion_matrix(y_test,Y_pred)\n",
    "# sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# SVCmodel.coef_\n",
    "# plt.hist(SVCmodel.coef_[0],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_map = vectorizer.vocabulary_\n",
    "# threshold = 1 \n",
    "# print(\"most negative words\")\n",
    "# for word,index in word_index_map.items():\n",
    "#     weight = SVCmodel.coef_[0][index]\n",
    "#     if weight < -threshold:\n",
    "#         print(word,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Pipeline in Sklearn to chain the steps of the workflow \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,\n",
    "                                                    stratify=y_res, \n",
    "                                                    test_size=0.25, random_state = 245)\n",
    "\n",
    "pipe = Pipeline([('vectorizer', tfidf),('LRmodel',LRmodel)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "model_evaluate(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pickle file to store and retrieve the object for future use\n",
    "with open('pipeline.pickle','wb') as f:\n",
    "    pickle.dump(pipe, f)\n",
    "    \n",
    "with open('pipeline.pickle', 'rb') as f:\n",
    "    loaded_pipe = pickle.load(f)\n",
    "    \n",
    "model_evaluate(loaded_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['I rate this product very very low',\n",
    "        'I love this project']\n",
    "# pred_test = tfidf.transform(test)\n",
    "# BNBmodel.predict(pred_test)\n",
    "# type(X_test)\n",
    "test = pd.Series(test)\n",
    "# pred_test = tfidf.transform(test)\n",
    "loaded_pipe.predict(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Count Vectorizer will be used and the performace of the model on the dataset will be compared to Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset to train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,\n",
    "                                                    stratify=y_res, \n",
    "                                                    test_size=0.25, random_state = 245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokenizer(doc):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(doc)\n",
    "    words_and_tags = nltk.pos_tag(tokens)\n",
    "    return [wnl.lemmatize(word, pos=get_wordnet_pos(tag)) \\\n",
    "            for word, tag in words_and_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_preprocessing(message):\n",
    "    Test_punc_removed = [word for word in message if word not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords and word.lower().isalpha() and word is not None]\n",
    "    Test_punc_removed_join_clean = ' '.join(Test_punc_removed_join_clean)\n",
    "    Test_punc_removed_join_clean= lemma_tokenizer(Test_punc_removed_join_clean)\n",
    "    # Test_punc_removed_join_clean = list(Test_punc_removed_join_clean)\n",
    "    return Test_punc_removed_join_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(message):\n",
    "    Test_punc_removed = [word for word in message if word not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords and word.lower().isalpha() and word is not None]\n",
    "    Test_punc_removed_join_clean = ' '.join(Test_punc_removed_join_clean)\n",
    "    return Test_punc_removed_join_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code sets up a CountVectorizer object with a custom tokenizer function, LemmaTokenizer(), and disables the lowercase option. It then uses the fitted CountVectorizer to transform the training data, X_train, into a document-term matrix and assigns the result to X_train. \n",
    "\n",
    "#### Finally, it transforms the test data, X_test, using the same vectorizer object and assigns the result to X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), lowercase=False)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447, 4034)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the X test dataset\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8765652951699463,\n",
       "  'recall': 0.677731673582296,\n",
       "  'f1-score': 0.7644305772230889,\n",
       "  'support': 723},\n",
       " '1': {'precision': 0.7376126126126126,\n",
       "  'recall': 0.9046961325966851,\n",
       "  'f1-score': 0.8126550868486353,\n",
       "  'support': 724},\n",
       " 'accuracy': 0.7912923289564616,\n",
       " 'macro avg': {'precision': 0.8070889538912794,\n",
       "  'recall': 0.7912139030894906,\n",
       "  'f1-score': 0.7885428320358621,\n",
       "  'support': 1447},\n",
       " 'weighted avg': {'precision': 0.8070409398337268,\n",
       "  'recall': 0.7912923289564616,\n",
       "  'f1-score': 0.7885594956535628,\n",
       "  'support': 1447}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using BernoulliNB \n",
    "BNBmodel = BernoulliNB(alpha = 1)\n",
    "BNBmodel.fit(X_train, y_train)\n",
    "model_evaluate(BNBmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['I strongly hate this product']\n",
    "# pred_test = tfidf.transform(test)\n",
    "# BNBmodel.predict(pred_test)\n",
    "# type(X_test)\n",
    "test = pd.Series(test)\n",
    "pred_test = vectorizer.transform(test)\n",
    "BNBmodel.predict(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       723\n",
      "           1       1.00      0.94      0.97       724\n",
      "\n",
      "    accuracy                           0.97      1447\n",
      "   macro avg       0.97      0.97      0.97      1447\n",
      "weighted avg       0.97      0.97      0.97      1447\n",
      " Train AUC 0.999106067269633 Test AUC 0.9915121157240778\n"
     ]
    }
   ],
   "source": [
    "# Using LogisticRegression\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 2000, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "model_evaluate(LRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       723\n",
      "           1       0.89      0.91      0.90       724\n",
      "\n",
      "    accuracy                           0.90      1447\n",
      "   macro avg       0.90      0.90      0.90      1447\n",
      "weighted avg       0.90      0.90      0.90      1447\n",
      " Train AUC 0.9715658217063652 Test AUC 0.9641361576610653\n"
     ]
    }
   ],
   "source": [
    "# Using Gradient Boosting Classifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)\n",
    "model_evaluate(GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       723\n",
      "           1       0.95      0.90      0.93       724\n",
      "\n",
      "    accuracy                           0.93      1447\n",
      "   macro avg       0.93      0.93      0.93      1447\n",
      "weighted avg       0.93      0.93      0.93      1447\n",
      " Train AUC 0.9913524888829399 Test AUC 0.9836011706899582\n"
     ]
    }
   ],
   "source": [
    "# Using MultinomialNB\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train, y_train)\n",
    "model_evaluate(NB_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moyin\\anaconda3\\envs\\sentiment\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       723\n",
      "           1       0.95      0.90      0.93       724\n",
      "\n",
      "    accuracy                           0.93      1447\n",
      "   macro avg       0.93      0.93      0.93      1447\n",
      "weighted avg       0.93      0.93      0.93      1447\n",
      " Train AUC 0.9913524888829399 Test AUC 0.9836011706899582\n"
     ]
    }
   ],
   "source": [
    "# Using a Pipeline in Sklearn to chain the steps of the workflow \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res,\n",
    "                                                    stratify=y_res, \n",
    "                                                    test_size=0.25, random_state = 245)\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer),('MNB',NB_classifier)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "model_evaluate(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       723\n",
      "           1       0.95      0.90      0.93       724\n",
      "\n",
      "    accuracy                           0.93      1447\n",
      "   macro avg       0.93      0.93      0.93      1447\n",
      "weighted avg       0.93      0.93      0.93      1447\n",
      " Train AUC 0.9913524888829399 Test AUC 0.9836011706899582\n"
     ]
    }
   ],
   "source": [
    "# Creating a pickle file to store and retrieve the object for future use\n",
    "with open('pipeline.pickle','wb') as f:\n",
    "    pickle.dump(pipe, f)\n",
    "    \n",
    "with open('pipeline.pickle', 'rb') as f:\n",
    "    loaded_vector_pipe = pickle.load(f)\n",
    "    \n",
    "model_evaluate(loaded_vector_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = ['I rate this product badly',\n",
    "#         'I love this project',\n",
    "#         'I am going to return this product',\n",
    "#         'I am very disappointed',\n",
    "#         'I will definitely return']\n",
    "# # pred_test = tfidf.transform(test)\n",
    "# # BNBmodel.predict(pred_test)\n",
    "# # type(X_test)\n",
    "# test = pd.Series(test)\n",
    "# # pred_test = tfidf.transform(test)\n",
    "# loaded_vector_pipe.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I rate this product badly', 1, 'Positive'), ('I love this project', 1, 'Positive'), ('I am going to return this product', 0, 'Negative')]\n"
     ]
    }
   ],
   "source": [
    "# A function that performs prediction according to the user input text\n",
    "def predict(model, user_text):\n",
    "    # Predict the sentiment\n",
    "    \n",
    "    # user_df = pd.DataFrame(user_text,columns=['user_text'])\n",
    "    # cleaned_input = user_df['user_text'].apply(preprocessing)\n",
    "    # input_feed = cleaned_input\n",
    "    # vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),lowercase=False)\n",
    "    # input_feed = vectorizer.transform(input_feed)\n",
    "    # predictions = model.predict(input_feed)\n",
    "\n",
    "\n",
    "    # preprocessed_text = user_preprocessing(user_text)\n",
    "    predictions = model.predict(user_text)\n",
    "    pred_to_label = {0: 'Negative', 1: 'Positive'}\n",
    "\n",
    "    # Make a list of user_text with sentiment.\n",
    "    data = []\n",
    "    for t, pred in zip(text, predictions):\n",
    "        data.append((t, pred, pred_to_label[pred]))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Text to classify should be in a list.\n",
    "    text = ['I rate this product badly',\n",
    "        'I love this project',\n",
    "        'I am going to return this product']\n",
    "    \n",
    "    predictions = predict(loaded_vector_pipe, text)\n",
    "    print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('sentiment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bd40f59161ef4fc1d720de42590e98cda6f25c47a5186167758fe09ff22edc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
